{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for scraping old projects whose project end date has passed\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "df = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "def soupconverter(url):  \n",
    "    html = urlopen(url)\n",
    "    soup = BeautifulSoup(html,'lxml')\n",
    "    return soup\n",
    "\n",
    "def data(url):\n",
    "    url = url[:-14] +'/comments'\n",
    "    soup = soupconverter(url)\n",
    "    head = soup.title.text.replace('\\n','')\n",
    "    \n",
    "    div = soup.find(\"div\",class_=\"project-profile__text_container col-4\")\n",
    "    intro = div.find(\"div\",class_=\"NS_project_profiles__blurb\").span.text.replace('\\n','')\n",
    "    backers = div.find(\"div\",class_=\"NS_campaigns__spotlight_stats\").b.text\n",
    "    pledged =div.find(\"div\",class_=\"NS_campaigns__spotlight_stats\").span.text\n",
    "\n",
    "    author = head\n",
    "    mystring= \" \"\n",
    "    mystring = mystring + author\n",
    "    value = mystring.index('by')\n",
    "    author = mystring[value+3:-14]\n",
    "    comments = soup.find_all(\"li\",{\"class\":\"NS_comments__comment\"})\n",
    "    output= \" \"\n",
    "    for comment in comments:\n",
    "\n",
    "        if comment.h3.a.text != author:\n",
    "            statement = comment.p.text.replace('\\n','') + '~'\n",
    "            output= output + statement\n",
    "    head = soup.title.text.replace('\\n','')    \n",
    "    return output,head,author,intro,backers,pledged\n",
    "\n",
    "def additionaldatas(url):\n",
    "    html = urlopen(url)\n",
    "    soup = BeautifulSoup(html,'lxml')\n",
    "    div2 = soup.find(\"div\",{\"class\":\"full-description\"})\n",
    "    about=\" \"\n",
    "    for data in div2.find_all('p'):\n",
    "        about= about + data.text\n",
    "    \n",
    "    file =[]\n",
    "\n",
    "    div = soup.find(\"div\",class_=\"col-right col-4 py3 border-left spotlight-project-video-archive\")\n",
    "    for span in div.find_all(\"span\",class_=\"money\"):\n",
    "         (file.append(span.text))\n",
    "\n",
    "    goal= (file[1])\n",
    "    \n",
    "    return about,goal    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "csv_data = pd.read_csv('Oldprojects.csv',encoding='latin-1').fillna(0)\n",
    "for i in csv_data['URL']:\n",
    "    if i != \"URL\":\n",
    "        comment,title,author,intro,backers,pledge = data(i)\n",
    "        about,goal = additionaldatas(i)\n",
    "        df =df.append({'title':title,'comment':comment,'Author':author,'About':about,'Short_Discription':intro,\n",
    "                       'day_remaining':day_remaining,'Fund':fund,'backers':backers,'pledge':pledge,\n",
    "                       'Results':project_status\n",
    "                       ,'URL':li},ignore_index=True)\n",
    "    \n",
    "#display(df)\n",
    "\n",
    "save=\"SecondData.csv\"\n",
    "df.to_csv(save)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
